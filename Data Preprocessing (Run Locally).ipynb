{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3374202a-0c6b-462b-bab5-415e9edca43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "The selected data files are quite large, so this data preprocessing was carried out on a local computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704c5e9c-4d05-469b-a75a-49fbb4bf92ec",
   "metadata": {},
   "source": [
    "**Import libraries**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "777e32bb-b711-4f61-be4f-67d963b441f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\miniconda\\envs\\research\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94ac113-91bf-46f6-bee5-5e855832fa9e",
   "metadata": {},
   "source": [
    "**step.1 Read data files**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e2afa9-cc26-4701-ab6b-b8df92778fd7",
   "metadata": {},
   "source": [
    "First, we read and checked the NetCDF dThe latitude and longitude variable names differ among files, so they need to be automatically detectedata files, including latitude/longitude coordinates and time range, to ensure the accuracy of subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2715eb1e-754e-4d13-bc3b-51703b57fdf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set path\n",
    "data_dir = Path(r'D:\\cangku\\data')\n",
    "\n",
    "# List of NetCDF files to analyze\n",
    "files = [\n",
    "    #gpp（abrupt-4xCO2，G1，piControl）\n",
    "    'gpp_Lmon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012.nc',\n",
    "    'gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc',\n",
    "    'gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912.nc',\n",
    "    #tos（abrupt-4xCO2，G1，piControl）\n",
    "    \"tos_Omon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012.nc\",\n",
    "    \"tos_Omon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc\",\n",
    "    \"tos_Omon_CanESM5_piControl_r1i1p2f1_gn_185001-194912.nc\",\n",
    "    #tas（abrupt-4xCO2，G1，piControl）\n",
    "    'tas_Amon_CanESM5_abrupt-4xCO2_185001-200012.nc',     \n",
    "    'tas_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc',\n",
    "    #pr（abrupt-4xCO2，G1，piControl）\n",
    "    'pr_Amon_CanESM5_abrupt-4xCO2_185001-200012.nc',   \n",
    "    'pr_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e60425ce-2c57-41c7-ba49-c3c8fef63b71",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The latitude and longitude variable names differ among files, so they need to be automatically detected\n",
    "def find_lat_lon_names(ds):\n",
    "    lat_name, lon_name = None, None\n",
    "    for candidate in ['lat', 'latitude', 'nav_lat', 'y']:\n",
    "        if candidate in ds.variables:\n",
    "            lat_name = candidate\n",
    "            break\n",
    "    for candidate in ['lon', 'longitude', 'nav_lon', 'x']:\n",
    "        if candidate in ds.variables:\n",
    "            lon_name = candidate\n",
    "            break\n",
    "    if lat_name is None or lon_name is None:\n",
    "        raise ValueError('Failed to automatically identify latitude and longitude variable names')\n",
    "    return lat_name, lon_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17b364dc-45da-4123-a59d-7b47a9db60de",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: gpp_Lmon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012.nc\n",
      "  Latitude dimensions: (64,)\n",
      "  Longitude dimensions: (128,)\n",
      "  Time dimension length: 1812\n",
      "  Time range: 1850-01-16 12:00:00 to 2000-12-16 12:00:00\n",
      "File: gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc\n",
      "  Latitude dimensions: (64,)\n",
      "  Longitude dimensions: (128,)\n",
      "  Time dimension length: 1200\n",
      "  Time range: 1850-01-16 12:00:00 to 1949-12-16 12:00:00\n",
      "File: gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912.nc\n",
      "  Latitude dimensions: (64,)\n",
      "  Longitude dimensions: (128,)\n",
      "  Time dimension length: 1200\n",
      "  Time range: 1850-01-15 00:00:00 to 1949-12-15 00:00:00\n",
      "File: tos_Omon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012.nc\n",
      "  Latitude dimensions: (291, 360)\n",
      "  Longitude dimensions: (291, 360)\n",
      "  Time dimension length: 1812\n",
      "  Time range: 1850-01-16 12:00:00 to 2000-12-16 12:00:00\n",
      "File: tos_Omon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc\n",
      "  Latitude dimensions: (291, 360)\n",
      "  Longitude dimensions: (291, 360)\n",
      "  Time dimension length: 1200\n",
      "  Time range: 1850-01-16 12:00:00 to 1949-12-16 12:00:00\n",
      "File: tos_Omon_CanESM5_piControl_r1i1p2f1_gn_185001-194912.nc\n",
      "  Latitude dimensions: (291, 360)\n",
      "  Longitude dimensions: (291, 360)\n",
      "  Time dimension length: 1200\n",
      "  Time range: 1850-01-15 00:00:00 to 1949-12-15 00:00:00\n",
      "File: tas_Amon_CanESM5_abrupt-4xCO2_185001-200012.nc\n",
      "  Latitude dimensions: (64,)\n",
      "  Longitude dimensions: (128,)\n",
      "  Time dimension length: 1812\n",
      "  Time range: 1850-01-16 12:00:00 to 2000-12-16 12:00:00\n",
      "File: tas_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc\n",
      "  Latitude dimensions: (64,)\n",
      "  Longitude dimensions: (128,)\n",
      "  Time dimension length: 1200\n",
      "  Time range: 1850-01-16 12:00:00 to 1949-12-16 12:00:00\n",
      "File: pr_Amon_CanESM5_abrupt-4xCO2_185001-200012.nc\n",
      "  Latitude dimensions: (64,)\n",
      "  Longitude dimensions: (128,)\n",
      "  Time dimension length: 1812\n",
      "  Time range: 1850-01-16 12:00:00 to 2000-12-16 12:00:00\n",
      "File: pr_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc\n",
      "  Latitude dimensions: (64,)\n",
      "  Longitude dimensions: (128,)\n",
      "  Time dimension length: 1200\n",
      "  Time range: 1850-01-16 12:00:00 to 1949-12-16 12:00:00\n"
     ]
    }
   ],
   "source": [
    "# Check each file and print a short summary\n",
    "def summarize_dataset(file_path):\n",
    "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "    with xr.open_dataset(file_path, decode_times=time_coder) as ds:\n",
    "        lat_name, lon_name = find_lat_lon_names(ds)    # Read different latitude and longitude names\n",
    "       \n",
    "        lat = ds[lat_name]\n",
    "        lon = ds[lon_name]\n",
    "        time = ds['time']\n",
    "\n",
    "        print(f'File: {file_path.name}')\n",
    "        print(f'  Latitude dimensions: {lat.shape}')\n",
    "        print(f'  Longitude dimensions: {lon.shape}')\n",
    "        print(f'  Time dimension length: {time.size}')\n",
    "        print(f'  Time range: {str(time.values[0])} to {str(time.values[-1])}')\n",
    "                \n",
    "for filename in files:\n",
    "    path = data_dir / filename\n",
    "    if path.exists():\n",
    "        try:\n",
    "            summarize_dataset(path)\n",
    "        except Exception:\n",
    "            print(f'Failed to read {filename}. Please verify the file content.')\n",
    "    else:\n",
    "        print(f'{filename} not found in the data directory.')\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd367c2-30e1-4726-a80d-783d8e467ae0",
   "metadata": {},
   "source": [
    "**step.2 Data processing **"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24aacfe-17fa-4c38-b8f4-74dcce73cc0a",
   "metadata": {},
   "source": [
    "2.1 Interpolation (unifying spatial resolution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab58bf2b-9ef9-458d-8a04-75ccc602ca0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Since the spatial resolutions of model outputs vary, all data were interpolated to a standard 1°×1° grid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b574438-13ff-45ba-abf5-5c6175ebe61e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define interpolation grid (1° × 1°)\n",
    "lon_target = np.arange(0, 360, 1) #The original longitude is 180°W–180°E, convert to 0–360 for easier calculation\n",
    "lat_target = np.arange(-90, 90, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a399d6af-f094-478a-b9ae-3f70fb1a4af2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Ensure all datasets have consistent latitude/longitude naming and coordinate systems\n",
    "\n",
    "def fix_lon(lon):\n",
    "    return lon % 360  #Convert longitude to the 0–360 range\n",
    "\n",
    "def standardize_coords(ds):\n",
    "    # Standardize latitude and longitude variable names\n",
    "    for lat_name in ['lat', 'latitude', 'nav_lat', 'y']:\n",
    "        if lat_name in ds:\n",
    "            ds = ds.rename({lat_name: 'lat'})\n",
    "            break\n",
    "    for lon_name in ['lon', 'longitude', 'nav_lon', 'x']:\n",
    "        if lon_name in ds:\n",
    "            ds = ds.rename({lon_name: 'lon'})\n",
    "            break\n",
    "\n",
    "    # tos data have 2D lat/lon, need to simplify to 1D\n",
    "    if ds['lon'].ndim == 2 and ds['lat'].ndim == 2:\n",
    "        lat_1d = ds['lat'][:, 0].values\n",
    "        lon_1d = ds['lon'][0, :].values\n",
    "        lon_1d = fix_lon(lon_1d)\n",
    "        ds = ds.drop_vars(['lon', 'lat'], errors='ignore')\n",
    "        ds = ds.rename({'j': 'lat', 'i': 'lon'})\n",
    "        ds = ds.assign_coords(lon=lon_1d, lat=lat_1d)\n",
    "\n",
    "    ds['lon'] = fix_lon(ds['lon'])\n",
    "    return ds.sortby('lon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5a3ce38-97ab-47f8-ba6c-1c2065c6d231",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: gpp_Lmon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1.nc\n",
      "Finished: gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1.nc\n",
      "Finished: gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1.nc\n",
      "Finished: tos_Omon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1.nc\n",
      "Finished: tos_Omon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1.nc\n",
      "Finished: tos_Omon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1.nc\n",
      "Finished: tas_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1.nc\n",
      "Finished: tas_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1.nc\n",
      "Finished: pr_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1.nc\n",
      "Finished: pr_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1.nc\n"
     ]
    }
   ],
   "source": [
    "#Define function for interpolating a single file\n",
    "def regrid(file):\n",
    "    with xr.open_dataset(file) as ds:\n",
    "        var = file.name.split('_')[0]\n",
    "        if var not in ds:\n",
    "            var = list(ds.data_vars)[0] \n",
    "\n",
    "        ds = ds[[var, 'time']]\n",
    "        ds = standardize_coords(ds)\n",
    "\n",
    "        ds_interp = ds.interp(lon=lon_target, lat=lat_target, method='linear') #Use linear interpolation to unify resolution\n",
    "\n",
    "        out_file = file.with_name(file.stem + '_1x1.nc')\n",
    "        ds_interp.to_netcdf(out_file)  \n",
    "\n",
    "        print(f'Finished: {out_file.name}')\n",
    "        \n",
    "#Execute interpolation\n",
    "for f in files:\n",
    "    file_path = data_dir / f\n",
    "    if file_path.exists():\n",
    "        try:\n",
    "            regrid(file_path)\n",
    "        except Exception as e:\n",
    "            print(f'Error: {f}, {e}') \n",
    "    else:\n",
    "        print(f'File not found: {f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a93662-0006-4c28-97b8-108fe5c5b235",
   "metadata": {},
   "source": [
    "**2.2 Detrend**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d820d-b419-4593-a8c5-63ebb5c8c5c9",
   "metadata": {
    "tags": []
   },
   "source": [
    "We performed detrending on the data to remove the effects of long-term external forcing (such as rising CO₂ or different model configurations) and to highlight the true response of terrestrial carbon fluxes to ENSO-related interannual climate variability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "07553883-d898-4291-9b8b-e078c88ea839",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_files = [\n",
    "    'gpp_Lmon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1.nc',\n",
    "    'gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1.nc',\n",
    "    'gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1.nc',\n",
    "    'tos_Omon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1.nc',\n",
    "    'tos_Omon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1.nc',\n",
    "    'tos_Omon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1.nc',\n",
    "    'tas_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1.nc',\n",
    "    'tas_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1.nc',\n",
    "    'pr_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1.nc',\n",
    "    'pr_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1.nc',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0ebffad-a565-40ef-828c-a1092443fcdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished: gpp_Lmon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1_1890-1949_detrend1.nc\n",
      "Finished: gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc\n",
      "Finished: gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc\n",
      "Finished: tos_Omon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1_1890-1949_detrend1.nc\n",
      "Finished: tos_Omon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc\n",
      "Finished: tos_Omon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc\n",
      "Finished: tas_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend1.nc\n",
      "Finished: tas_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc\n",
      "Finished: pr_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend1.nc\n",
      "Finished: pr_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc\n"
     ]
    }
   ],
   "source": [
    "#Define detrending function\n",
    "def detrend(data):\n",
    "    t, nlat, nlon = data.shape\n",
    "    time_index = np.arange(t)\n",
    "    out = np.full_like(data, np.nan)\n",
    "\n",
    "    for i in range(nlat):\n",
    "        for j in range(nlon):\n",
    "            y = data[:, i, j]\n",
    "            if np.isfinite(y).sum() < 2:\n",
    "                continue\n",
    "            p = np.polyfit(time_index, y, 1) #Least squares method\n",
    "            out[:, i, j] = y - np.polyval(p, time_index)\n",
    "    return out\n",
    "\n",
    "def process_one(path):\n",
    "    with xr.open_dataset(path) as ds:\n",
    "        var = next((v for v in ['gpp', 'tos', 'tas', 'pr'] if v in ds), None)\n",
    "        if not var:\n",
    "            print(f'Skipped {path.name}, main variable not found.')\n",
    "            return\n",
    "        da = ds[var].sel(time=slice('1890-01', '1949-12')).astype('float64') # Detrending period: 1890–1949\n",
    "        detrended = detrend(da.values)\n",
    "\n",
    "        da_dt = xr.DataArray(\n",
    "            detrended, coords=da.coords, dims=da.dims, name=var, attrs=da.attrs\n",
    "        )\n",
    "\n",
    "        out_path = path.with_name(path.stem + '_1890-1949_detrend1.nc')\n",
    "        da_dt.to_netcdf(out_path)\n",
    "        print(f'Finished: {out_path.name}')\n",
    "\n",
    "# Batch detrending\n",
    "for fname in input_files:\n",
    "    path = data_dir / fname\n",
    "    if path.exists():\n",
    "        try:\n",
    "            process_one(path)\n",
    "        except Exception as e:\n",
    "            print(f'Error processing {fname}: {e}')\n",
    "    else:\n",
    "        print(f'File not found: {fname}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a80a52c-e58b-4dc6-ba9c-65203446cbc7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpp_Lmon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1_1890-1949_detrend1.nc: Latitude cropped to -40° ~ 40°\n",
      "Saved: gpp_Lmon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1_1890-1949_detrend.nc\n",
      "\n",
      "gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc: Latitude cropped to -40° ~ 40°\n",
      "Saved: gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend.nc\n",
      "\n",
      "gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc: Latitude cropped to -40° ~ 40°\n",
      "Saved: gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend.nc\n",
      "\n",
      "pr_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend1.nc: Latitude cropped to -40° ~ 40°\n",
      "Saved: pr_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend.nc\n",
      "\n",
      "pr_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc: Latitude cropped to -40° ~ 40°\n",
      "Saved: pr_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend.nc\n",
      "\n",
      "tas_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend1.nc: Latitude cropped to -40° ~ 40°\n",
      "Saved: tas_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend.nc\n",
      "\n",
      "tas_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc: Latitude cropped to -40° ~ 40°\n",
      "Saved: tas_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend.nc\n",
      "\n",
      "tos_Omon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1_1890-1949_detrend1.nc: Latitude cropped to -5° ~ 5°\n",
      "Saved: tos_Omon_CanESM5_abrupt-4xCO2_r1i1p2f1_gn_185001-200012_1x1_1890-1949_detrend.nc\n",
      "\n",
      "tos_Omon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc: Latitude cropped to -5° ~ 5°\n",
      "Saved: tos_Omon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend.nc\n",
      "\n",
      "tos_Omon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend1.nc: Latitude cropped to -5° ~ 5°\n",
      "Saved: tos_Omon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend.nc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Read all files, crop latitude (40° for others; ±5° for tos), and convert to float32\n",
    "files = sorted(data_dir.glob(\"*_detrend1.nc\"))\n",
    "\n",
    "def crop_and_compress(path):\n",
    "    try:\n",
    "        with xr.open_dataset(path) as ds:\n",
    "            # Standardize latitude and longitude variable names\n",
    "            lat_name = None\n",
    "            for name in [\"lat\", \"latitude\", \"nav_lat\"]:\n",
    "                if name in ds.coords:\n",
    "                    lat_name = name\n",
    "                    break\n",
    "\n",
    "            # Determine cropping range: 40° for most variables, ±5° for tos\n",
    "            if \"tos\" in path.name:\n",
    "                lat_range = slice(-5, 5)\n",
    "            else:\n",
    "                lat_range = slice(-40, 40)\n",
    "\n",
    "            # Apply cropping only if latitude is 1D\n",
    "            if lat_name and ds[lat_name].ndim == 1:\n",
    "                ds = ds.sel({lat_name: lat_range})\n",
    "                print(f\"{path.name}: Latitude cropped to {lat_range.start}° ~ {lat_range.stop}°\")\n",
    "            else:\n",
    "                print(f\"{path.name}: Unable to crop (latitude is 2D or missing), compression only\")\n",
    "\n",
    "            # Convert to float32 (reduce storage size and make computation faster)\n",
    "            ds32 = ds.astype(\"float32\")\n",
    "\n",
    "           \n",
    "            new_name = path.name.replace(\"detrend1.nc\", \"detrend.nc\")\n",
    "            out_path = path.with_name(new_name)\n",
    "\n",
    "            # Set compression parameters\n",
    "            encoding = {\n",
    "                var: {\"zlib\": True, \"complevel\": 4, \"dtype\": \"f4\"}\n",
    "                for var in ds32.data_vars\n",
    "            }\n",
    "\n",
    "            ds32.to_netcdf(out_path, encoding=encoding)\n",
    "            print(f\"Saved: {out_path.name}\\n\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {path.name}: {e}\\n\")\n",
    "\n",
    "\n",
    "# === Batch execution ===\n",
    "for f in files:\n",
    "    crop_and_compress(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6550840c-c5c7-46aa-a5a3-e3421d79befa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[finish] tas annual mean saved → tas_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend_annual_1890-1949.nc, shape=(60, 81, 360)\n",
      "[finish] tas annual mean saved → tas_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend_annual_1890-1949.nc, shape=(60, 81, 360)\n",
      "[finish] pr annual mean saved → pr_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend_annual_1890-1949.nc, shape=(60, 81, 360)\n",
      "[finish] pr annual mean saved → pr_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend_annual_1890-1949.nc, shape=(60, 81, 360)\n",
      "=== all finished ===\n"
     ]
    }
   ],
   "source": [
    "#Convert monthly temperature (tas) and precipitation (pr) data to annual mean values (1890–1949)\n",
    "\n",
    "DATA_DIR = Path(r'D:\\cangku\\data')\n",
    "\n",
    "TAS_FILES = {\n",
    "    'abrupt-4xCO2': 'tas_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend.nc',\n",
    "    'G1': 'tas_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend.nc',\n",
    "}\n",
    "\n",
    "PR_FILES = {\n",
    "    'abrupt-4xCO2': 'pr_Amon_CanESM5_abrupt-4xCO2_185001-200012_1x1_1890-1949_detrend.nc',\n",
    "    'G1': 'pr_Amon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_1890-1949_detrend.nc',\n",
    "}\n",
    "LAT_SLICE = slice(-40, 40)\n",
    "\n",
    "\n",
    "def _std_coords(ds):\n",
    "    if 'latitude' in ds.coords:\n",
    "        ds = ds.rename({'latitude': 'lat'})\n",
    "    if 'longitude' in ds.coords:\n",
    "        ds = ds.rename({'longitude': 'lon'})\n",
    "    if 'lon' in ds.coords and float(ds['lon'].min()) < 0:\n",
    "        ds = ds.assign_coords(lon=(ds['lon'] % 360)).sortby('lon')\n",
    "    return ds\n",
    "\n",
    "def compute_annual_mean_field(path: Path, varname: str):   \n",
    "    ds = xr.open_dataset(path)\n",
    "    ds = _std_coords(ds)\n",
    "\n",
    "    # Identify Variable\n",
    "    if varname not in ds.data_vars:\n",
    "        varname = list(ds.data_vars)[0]\n",
    "    da = ds[varname].sel(lat=LAT_SLICE)\n",
    "\n",
    "    # convert to annual mean\n",
    "    annual = da.resample(time='YS').mean().sel(time=slice('1890', '1949'))\n",
    "    annual = annual.astype('float32')\n",
    "\n",
    "    ds.close()\n",
    "    return annual\n",
    "\n",
    "\n",
    "def process_and_save(file_dict, varname):\n",
    "    for exp, fname in file_dict.items():\n",
    "        in_path = DATA_DIR / fname\n",
    "        da_ann = compute_annual_mean_field(in_path, varname)\n",
    "        out_name = fname.replace('.nc', '_annual_1890-1949.nc')\n",
    "        out_path = DATA_DIR / out_name\n",
    "        da_ann.to_netcdf(out_path)\n",
    "        print(f'[finish] {varname} annual mean saved → {out_path.name}, shape={da_ann.shape}')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_and_save(TAS_FILES, 'tas')\n",
    "    process_and_save(PR_FILES, 'pr')\n",
    "    print(' all finished ')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
